y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
^C
[ec2-user@ip-172-31-28-131 ~]$ ^C
[ec2-user@ip-172-31-28-131 ~]$ ^C
[ec2-user@ip-172-31-28-131 ~]$ ^C
[ec2-user@ip-172-31-28-131 ~]$ sudo service jenkins restart
Restarting jenkins (via systemctl):  y
                                                           [  OK  ]
[ec2-user@ip-172-31-28-131 ~]$ y
-bash: y: command not found
[ec2-user@ip-172-31-28-131 ~]$ sudo systemctl daemon-reload
[ec2-user@ip-172-31-28-131 ~]$ sudo service docker stop
Redirecting to /bin/systemctl stop docker.service
Warning: Stopping docker.service, but it can still be activated by:
  docker.socket
[ec2-user@ip-172-31-28-131 ~]$ sudo service docker start
Redirecting to /bin/systemctl start docker.service
[ec2-user@ip-172-31-28-131 ~]$ sudo cat /var/lib/jenkins/secrets/initialAdminPassword
6e9879db71954b7b9e01e23c9e5b1105
[ec2-user@ip-172-31-28-131 ~]$ 6e9879db71954b7b9e01e23c9e5b1105^C
[ec2-user@ip-172-31-28-131 ~]$ sudo yum install -y kubectl
Loaded plugins: extras_suggestions, langpacks, priorities, update-motd
amzn2-core                                                                                                                                                            | 3.7 kB  00:00:00
No package kubectl available.
Error: Nothing to do
[ec2-user@ip-172-31-28-131 ~]$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo yum add -
Loaded plugins: extras_suggestions, langpacks, priorities, update-motd
No such command: add. Please use /bin/yum --help
[ec2-user@ip-172-31-28-131 ~]$ ls /usr/share/maven
bin  boot  conf  lib
[ec2-user@ip-172-31-28-131 ~]$ git
-bash: git: command not found
[ec2-user@ip-172-31-28-131 ~]$ sudo yum install git -y
Loaded plugins: extras_suggestions, langpacks, priorities, update-motd
amzn2-core                                                                                                                                                            | 3.7 kB  00:00:00
Resolving Dependencies
--> Running transaction check
---> Package git.x86_64 0:2.37.1-1.amzn2.0.1 will be installed
--> Processing Dependency: perl-Git = 2.37.1-1.amzn2.0.1 for package: git-2.37.1-1.amzn2.0.1.x86_64
--> Processing Dependency: git-core-doc = 2.37.1-1.amzn2.0.1 for package: git-2.37.1-1.amzn2.0.1.x86_64
--> Processing Dependency: git-core = 2.37.1-1.amzn2.0.1 for package: git-2.37.1-1.amzn2.0.1.x86_64
--> Processing Dependency: perl(Term::ReadKey) for package: git-2.37.1-1.amzn2.0.1.x86_64
--> Processing Dependency: perl(Git::I18N) for package: git-2.37.1-1.amzn2.0.1.x86_64
--> Processing Dependency: perl(Git) for package: git-2.37.1-1.amzn2.0.1.x86_64
--> Running transaction check
---> Package git-core.x86_64 0:2.37.1-1.amzn2.0.1 will be installed
---> Package git-core-doc.noarch 0:2.37.1-1.amzn2.0.1 will be installed
---> Package perl-Git.noarch 0:2.37.1-1.amzn2.0.1 will be installed
--> Processing Dependency: perl(Error) for package: perl-Git-2.37.1-1.amzn2.0.1.noarch
---> Package perl-TermReadKey.x86_64 0:2.30-20.amzn2.0.2 will be installed
--> Running transaction check
---> Package perl-Error.noarch 1:0.17020-2.amzn2 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

=============================================================================================================================================================================================
 Package                                          Arch                                   Version                                            Repository                                  Size
=============================================================================================================================================================================================
Installing:
 git                                              x86_64                                 2.37.1-1.amzn2.0.1                                 amzn2-core                                  71 k
Installing for dependencies:
 git-core                                         x86_64                                 2.37.1-1.amzn2.0.1                                 amzn2-core                                 6.4 M
 git-core-doc                                     noarch                                 2.37.1-1.amzn2.0.1                                 amzn2-core                                 2.8 M
 perl-Error                                       noarch                                 1:0.17020-2.amzn2                                  amzn2-core                                  32 k
 perl-Git                                         noarch                                 2.37.1-1.amzn2.0.1                                 amzn2-core                                  46 k
 perl-TermReadKey                                 x86_64                                 2.30-20.amzn2.0.2                                  amzn2-core                                  31 k

Transaction Summary
=============================================================================================================================================================================================
Install  1 Package (+5 Dependent packages)

Total download size: 9.3 M
Installed size: 40 M
Downloading packages:
(1/6): git-2.37.1-1.amzn2.0.1.x86_64.rpm                                                                                                                              |  71 kB  00:00:00
(2/6): git-core-doc-2.37.1-1.amzn2.0.1.noarch.rpm                                                                                                                     | 2.8 MB  00:00:00
(3/6): perl-Error-0.17020-2.amzn2.noarch.rpm                                                                                                                          |  32 kB  00:00:00
(4/6): git-core-2.37.1-1.amzn2.0.1.x86_64.rpm                                                                                                                         | 6.4 MB  00:00:00
(5/6): perl-Git-2.37.1-1.amzn2.0.1.noarch.rpm                                                                                                                         |  46 kB  00:00:00
(6/6): perl-TermReadKey-2.30-20.amzn2.0.2.x86_64.rpm                                                                                                                  |  31 kB  00:00:00
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total                                                                                                                                                         32 MB/s | 9.3 MB  00:00:00
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : git-core-2.37.1-1.amzn2.0.1.x86_64                                                                                                                                        1/6
  Installing : git-core-doc-2.37.1-1.amzn2.0.1.noarch                                                                                                                                    2/6
  Installing : 1:perl-Error-0.17020-2.amzn2.noarch                                                                                                                                       3/6
  Installing : perl-TermReadKey-2.30-20.amzn2.0.2.x86_64                                                                                                                                 4/6
  Installing : perl-Git-2.37.1-1.amzn2.0.1.noarch                                                                                                                                        5/6
  Installing : git-2.37.1-1.amzn2.0.1.x86_64                                                                                                                                             6/6
  Verifying  : perl-TermReadKey-2.30-20.amzn2.0.2.x86_64                                                                                                                                 1/6
  Verifying  : git-core-doc-2.37.1-1.amzn2.0.1.noarch                                                                                                                                    2/6
  Verifying  : perl-Git-2.37.1-1.amzn2.0.1.noarch                                                                                                                                        3/6
  Verifying  : git-2.37.1-1.amzn2.0.1.x86_64                                                                                                                                             4/6
  Verifying  : git-core-2.37.1-1.amzn2.0.1.x86_64                                                                                                                                        5/6
  Verifying  : 1:perl-Error-0.17020-2.amzn2.noarch                                                                                                                                       6/6

Installed:
  git.x86_64 0:2.37.1-1.amzn2.0.1

Dependency Installed:
  git-core.x86_64 0:2.37.1-1.amzn2.0.1               git-core-doc.noarch 0:2.37.1-1.amzn2.0.1        perl-Error.noarch 1:0.17020-2.amzn2        perl-Git.noarch 0:2.37.1-1.amzn2.0.1
  perl-TermReadKey.x86_64 0:2.30-20.amzn2.0.2

Complete!
[ec2-user@ip-172-31-28-131 ~]$ ls /usr/share/git
ls: cannot access /usr/share/git: No such file or directory
[ec2-user@ip-172-31-28-131 ~]$ git -version
unknown option: -version
usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]
           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]
           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]
           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]
           [--super-prefix=<path>] [--config-env=<name>=<envvar>]
           <command> [<args>]
[ec2-user@ip-172-31-28-131 ~]$ docker -version
unknown shorthand flag: 'e' in -ersion
See 'docker --help'.

Usage:  docker [OPTIONS] COMMAND

A self-sufficient runtime for containers

Options:
      --config string      Location of client config files (default "/home/ec2-user/.docker")
  -c, --context string     Name of the context to use to connect to the daemon (overrides DOCKER_HOST env var and default context set with "docker context use")
  -D, --debug              Enable debug mode
  -H, --host list          Daemon socket(s) to connect to
  -l, --log-level string   Set the logging level ("debug"|"info"|"warn"|"error"|"fatal") (default "info")
      --tls                Use TLS; implied by --tlsverify
      --tlscacert string   Trust certs signed only by this CA (default "/home/ec2-user/.docker/ca.pem")
      --tlscert string     Path to TLS certificate file (default "/home/ec2-user/.docker/cert.pem")
      --tlskey string      Path to TLS key file (default "/home/ec2-user/.docker/key.pem")
      --tlsverify          Use TLS and verify the remote
  -v, --version            Print version information and quit

Management Commands:
  builder     Manage builds
  config      Manage Docker configs
  container   Manage containers
  context     Manage contexts
  image       Manage images
  manifest    Manage Docker image manifests and manifest lists
  network     Manage networks
  node        Manage Swarm nodes
  plugin      Manage plugins
  secret      Manage Docker secrets
  service     Manage services
  stack       Manage Docker stacks
  swarm       Manage Swarm
  system      Manage Docker
  trust       Manage trust on Docker images
  volume      Manage volumes

Commands:
  attach      Attach local standard input, output, and error streams to a running container
  build       Build an image from a Dockerfile
  commit      Create a new image from a container's changes
  cp          Copy files/folders between a container and the local filesystem
  create      Create a new container
  diff        Inspect changes to files or directories on a container's filesystem
  events      Get real time events from the server
  exec        Run a command in a running container
  export      Export a container's filesystem as a tar archive
  history     Show the history of an image
  images      List images
  import      Import the contents from a tarball to create a filesystem image
  info        Display system-wide information
  inspect     Return low-level information on Docker objects
  kill        Kill one or more running containers
  load        Load an image from a tar archive or STDIN
  login       Log in to a Docker registry
  logout      Log out from a Docker registry
  logs        Fetch the logs of a container
  pause       Pause all processes within one or more containers
  port        List port mappings or a specific mapping for the container
  ps          List containers
  pull        Pull an image or a repository from a registry
  push        Push an image or a repository to a registry
  rename      Rename a container
  restart     Restart one or more containers
  rm          Remove one or more containers
  rmi         Remove one or more images
  run         Run a command in a new container
  save        Save one or more images to a tar archive (streamed to STDOUT by default)
  search      Search the Docker Hub for images
  start       Start one or more stopped containers
  stats       Display a live stream of container(s) resource usage statistics
  stop        Stop one or more running containers
  tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE
  top         Display the running processes of a container
  unpause     Unpause all processes within one or more containers
  update      Update configuration of one or more containers
  version     Show the Docker version information
  wait        Block until one or more containers stop, then print their exit codes

Run 'docker COMMAND --help' for more information on a command.

To get more help with docker, check out our guides at https://docs.docker.com/go/guides/

[ec2-user@ip-172-31-28-131 ~]$ docker run -p 5000:5000 nginx
Unable to find image 'nginx:latest' locally
latest: Pulling from library/nginx
7a6db449b51b: Pull complete
ca1981974b58: Pull complete
d4019c921e20: Pull complete
7cb804d746d4: Pull complete
e7a561826262: Pull complete
7247f6e5c182: Pull complete
Digest: sha256:b95a99feebf7797479e0c5eb5ec0bdfa5d9f504bc94da550c2f58e839ea6914f
Status: Downloaded newer image for nginx:latest
/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2022/08/29 17:35:21 [notice] 1#1: using the "epoll" event method
2022/08/29 17:35:21 [notice] 1#1: nginx/1.23.1
2022/08/29 17:35:21 [notice] 1#1: built by gcc 10.2.1 20210110 (Debian 10.2.1-6)
2022/08/29 17:35:21 [notice] 1#1: OS: Linux 4.14.287-215.504.amzn2.x86_64
2022/08/29 17:35:21 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 32768:65536
2022/08/29 17:35:21 [notice] 1#1: start worker processes
2022/08/29 17:35:21 [notice] 1#1: start worker process 31
^C2022/08/29 17:36:19 [notice] 1#1: signal 2 (SIGINT) received, exiting
2022/08/29 17:36:19 [notice] 31#31: exiting
2022/08/29 17:36:19 [notice] 31#31: exit
2022/08/29 17:36:19 [notice] 1#1: signal 17 (SIGCHLD) received from 31
2022/08/29 17:36:19 [notice] 1#1: worker process 31 exited with code 0
2022/08/29 17:36:19 [notice] 1#1: exit
[ec2-user@ip-172-31-28-131 ~]$ curl https://registry-1.docker.io/v2/ && echo
{"errors":[{"code":"UNAUTHORIZED","message":"authentication required","detail":null}]}

[ec2-user@ip-172-31-28-131 ~]$ docker login
Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.
Username: asecurityguru
Password:
Error response from daemon: Get "https://registry-1.docker.io/v2/": Get "https://auth.docker.io/token?account=asecurityguru&client_id=docker&offline_token=true&service=registry.docker.io": EOF
[ec2-user@ip-172-31-28-131 ~]$ docker logout
Removing login credentials for https://index.docker.io/v1/
[ec2-user@ip-172-31-28-131 ~]$ docker login
Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.
Username: asecurityguru
Password:
WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded
[ec2-user@ip-172-31-28-131 ~]$ curl https://registry-1.docker.io/v2/ && echo
{"errors":[{"code":"UNAUTHORIZED","message":"authentication required","detail":null}]}

[ec2-user@ip-172-31-28-131 ~]$ curl https://registry-1.docker.io/v1/ && echo
<html><body><h1>503 Service Unavailable</h1>
No server is available to handle this request.
</body></html>


[ec2-user@ip-172-31-28-131 ~]$ curl -o kubectl https://s3.us-west-2.amazonaws.com/amazon-eks/1.23.7/2022-06-29/bin/linux/amd64/kubectl
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 44.4M  100 44.4M    0     0  41.5M      0  0:00:01  0:00:01 --:--:-- 41.5M
[ec2-user@ip-172-31-28-131 ~]$ kubectl
-bash: kubectl: command not found
[ec2-user@ip-172-31-28-131 ~]$ chmod +x ./kubectl
[ec2-user@ip-172-31-28-131 ~]$ mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin
[ec2-user@ip-172-31-28-131 ~]$ kubectl -version
error: invalid argument "ersion" for "-v, --v" flag: strconv.ParseInt: parsing "ersion": invalid syntax
See 'kubectl --help' for usage.
[ec2-user@ip-172-31-28-131 ~]$ kubectl
kubectl controls the Kubernetes cluster manager.

 Find more information at: https://kubernetes.io/docs/reference/kubectl/overview/

Basic Commands (Beginner):
  create        Create a resource from a file or from stdin
  expose        Take a replication controller, service, deployment or pod and expose it as a new Kubernetes service
  run           Run a particular image on the cluster
  set           Set specific features on objects

Basic Commands (Intermediate):
  explain       Get documentation for a resource
  get           Display one or many resources
  edit          Edit a resource on the server
  delete        Delete resources by file names, stdin, resources and names, or by resources and label selector

Deploy Commands:
  rollout       Manage the rollout of a resource
  scale         Set a new size for a deployment, replica set, or replication controller
  autoscale     Auto-scale a deployment, replica set, stateful set, or replication controller

Cluster Management Commands:
  certificate   Modify certificate resources.
  cluster-info  Display cluster information
  top           Display resource (CPU/memory) usage
  cordon        Mark node as unschedulable
  uncordon      Mark node as schedulable
  drain         Drain node in preparation for maintenance
  taint         Update the taints on one or more nodes

Troubleshooting and Debugging Commands:
  describe      Show details of a specific resource or group of resources
  logs          Print the logs for a container in a pod
  attach        Attach to a running container
  exec          Execute a command in a container
  port-forward  Forward one or more local ports to a pod
  proxy         Run a proxy to the Kubernetes API server
  cp            Copy files and directories to and from containers
  auth          Inspect authorization
  debug         Create debugging sessions for troubleshooting workloads and nodes

Advanced Commands:
  diff          Diff the live version against a would-be applied version
  apply         Apply a configuration to a resource by file name or stdin
  patch         Update fields of a resource
  replace       Replace a resource by file name or stdin
  wait          Experimental: Wait for a specific condition on one or many resources
  kustomize     Build a kustomization target from a directory or URL.

Settings Commands:
  label         Update the labels on a resource
  annotate      Update the annotations on a resource
  completion    Output shell completion code for the specified shell (bash, zsh or fish)

Other Commands:
  alpha         Commands for features in alpha
  api-resources Print the supported API resources on the server
  api-versions  Print the supported API versions on the server, in the form of "group/version"
  config        Modify kubeconfig files
  plugin        Provides utilities for interacting with plugins
  version       Print the client and server version information

Usage:
  kubectl [flags] [options]

Use "kubectl <command> --help" for more information about a given command.
Use "kubectl options" for a list of global command-line options (applies to all commands).
[ec2-user@ip-172-31-28-131 ~]$ ls /usr/local/bin/kubectl
ls: cannot access /usr/local/bin/kubectl: No such file or directory
[ec2-user@ip-172-31-28-131 ~]$ ls
aws  awscliv2.zip  bin  kubectl
[ec2-user@ip-172-31-28-131 ~]$ cp kubectl /usr/local/bin/
cp: cannot create regular file ‘/usr/local/bin/kubectl’: Permission denied
[ec2-user@ip-172-31-28-131 ~]$ sudo cp kubectl /usr/local/bin/
[ec2-user@ip-172-31-28-131 ~]$ kubectl
kubectl controls the Kubernetes cluster manager.

 Find more information at: https://kubernetes.io/docs/reference/kubectl/overview/

Basic Commands (Beginner):
  create        Create a resource from a file or from stdin
  expose        Take a replication controller, service, deployment or pod and expose it as a new Kubernetes service
  run           Run a particular image on the cluster
  set           Set specific features on objects

Basic Commands (Intermediate):
  explain       Get documentation for a resource
  get           Display one or many resources
  edit          Edit a resource on the server
  delete        Delete resources by file names, stdin, resources and names, or by resources and label selector

Deploy Commands:
  rollout       Manage the rollout of a resource
  scale         Set a new size for a deployment, replica set, or replication controller
  autoscale     Auto-scale a deployment, replica set, stateful set, or replication controller

Cluster Management Commands:
  certificate   Modify certificate resources.
  cluster-info  Display cluster information
  top           Display resource (CPU/memory) usage
  cordon        Mark node as unschedulable
  uncordon      Mark node as schedulable
  drain         Drain node in preparation for maintenance
  taint         Update the taints on one or more nodes

Troubleshooting and Debugging Commands:
  describe      Show details of a specific resource or group of resources
  logs          Print the logs for a container in a pod
  attach        Attach to a running container
  exec          Execute a command in a container
  port-forward  Forward one or more local ports to a pod
  proxy         Run a proxy to the Kubernetes API server
  cp            Copy files and directories to and from containers
  auth          Inspect authorization
  debug         Create debugging sessions for troubleshooting workloads and nodes

Advanced Commands:
  diff          Diff the live version against a would-be applied version
  apply         Apply a configuration to a resource by file name or stdin
  patch         Update fields of a resource
  replace       Replace a resource by file name or stdin
  wait          Experimental: Wait for a specific condition on one or many resources
  kustomize     Build a kustomization target from a directory or URL.

Settings Commands:
  label         Update the labels on a resource
  annotate      Update the annotations on a resource
  completion    Output shell completion code for the specified shell (bash, zsh or fish)

Other Commands:
  alpha         Commands for features in alpha
  api-resources Print the supported API resources on the server
  api-versions  Print the supported API versions on the server, in the form of "group/version"
  config        Modify kubeconfig files
  plugin        Provides utilities for interacting with plugins
  version       Print the client and server version information

Usage:
  kubectl [flags] [options]

Use "kubectl <command> --help" for more information about a given command.
Use "kubectl options" for a list of global command-line options (applies to all commands).
[ec2-user@ip-172-31-28-131 ~]$ git^C
[ec2-user@ip-172-31-28-131 ~]$ sudo cat /var/lib/jenkins/secrets/initialAdminPassword
6e9879db71954b7b9e01e23c9e5b1105
[ec2-user@ip-172-31-28-131 ~]$ 6e9879db71954b7b9e01e23c9e5b1105^C
[ec2-user@ip-172-31-28-131 ~]$ kubectl get pods
error: the server doesn't have a resource type "pods"
[ec2-user@ip-172-31-28-131 ~]$ kubectl config view
apiVersion: v1
clusters: null
contexts: null
current-context: ""
kind: Config
preferences: {}
users: null
[ec2-user@ip-172-31-28-131 ~]$ kubectl get nodes
error: the server doesn't have a resource type "nodes"
[ec2-user@ip-172-31-28-131 ~]$ aws sts get-caller-identity
{
    "UserId": "AROASD7MVJNKVYFQGU2BU:i-0287972da825e3a88",
    "Account": "145988340565",
    "Arn": "arn:aws:sts::145988340565:assumed-role/eks-admin/i-0287972da825e3a88"
}
[ec2-user@ip-172-31-28-131 ~]$ aws eks --region region update-kubeconfig --name test-cluster1

Could not connect to the endpoint URL: "https://eks.region.amazonaws.com/clusters/test-cluster1"
[ec2-user@ip-172-31-28-131 ~]$ sudo yum install eksctl
Loaded plugins: extras_suggestions, langpacks, priorities, update-motd
amzn2-core                                                                                                                                                            | 3.7 kB  00:00:00
No package eksctl available.
Error: Nothing to do
[ec2-user@ip-172-31-28-131 ~]$ curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp

[ec2-user@ip-172-31-28-131 ~]$
[ec2-user@ip-172-31-28-131 ~]$ sudo mv /tmp/eksctl /usr/local/bin
[ec2-user@ip-172-31-28-131 ~]$
[ec2-user@ip-172-31-28-131 ~]$ eksctl version
0.109.0
[ec2-user@ip-172-31-28-131 ~]$ eksctl create cluster --name test-cluster --version 1.23 --region us-west-2 --nodegroup-name linux-nodes --node-type t2.micro --nodes 1
2022-08-29 18:34:12 [ℹ]  eksctl version 0.109.0
2022-08-29 18:34:12 [ℹ]  using region us-west-2
2022-08-29 18:34:12 [ℹ]  skipping us-west-2d from selection because it doesn't support the following instance type(s): t2.micro
2022-08-29 18:34:12 [ℹ]  setting availability zones to [us-west-2a us-west-2c us-west-2b]
2022-08-29 18:34:12 [ℹ]  subnets for us-west-2a - public:192.168.0.0/19 private:192.168.96.0/19
2022-08-29 18:34:12 [ℹ]  subnets for us-west-2c - public:192.168.32.0/19 private:192.168.128.0/19
2022-08-29 18:34:12 [ℹ]  subnets for us-west-2b - public:192.168.64.0/19 private:192.168.160.0/19
2022-08-29 18:34:12 [ℹ]  nodegroup "linux-nodes" will use "" [AmazonLinux2/1.23]
2022-08-29 18:34:12 [ℹ]  using Kubernetes version 1.23
2022-08-29 18:34:12 [ℹ]  creating EKS cluster "test-cluster" in "us-west-2" region with managed nodes
2022-08-29 18:34:12 [ℹ]  will create 2 separate CloudFormation stacks for cluster itself and the initial managed nodegroup
2022-08-29 18:34:12 [ℹ]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-west-2 --cluster=test-cluster'
2022-08-29 18:34:12 [ℹ]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "test-cluster" in "us-west-2"
2022-08-29 18:34:12 [ℹ]  CloudWatch logging will not be enabled for cluster "test-cluster" in "us-west-2"
2022-08-29 18:34:12 [ℹ]  you can enable it with 'eksctl utils update-cluster-logging --enable-types={SPECIFY-YOUR-LOG-TYPES-HERE (e.g. all)} --region=us-west-2 --cluster=test-cluster'
2022-08-29 18:34:12 [ℹ]
2 sequential tasks: { create cluster control plane "test-cluster",
    2 sequential sub-tasks: {
        wait for control plane to become ready,
        create managed nodegroup "linux-nodes",
    }
}
2022-08-29 18:34:12 [ℹ]  building cluster stack "eksctl-test-cluster-cluster"
2022-08-29 18:34:12 [!]  1 error(s) occurred and cluster hasn't been created properly, you may wish to check CloudFormation console
2022-08-29 18:34:12 [ℹ]  to cleanup resources, run 'eksctl delete cluster --region=us-west-2 --name=test-cluster'
2022-08-29 18:34:12 [✖]  creating CloudFormation stack "eksctl-test-cluster-cluster": operation error CloudFormation: CreateStack, https response error StatusCode: 400, RequestID: 6be537a1-7a23-40d7-93f2-16caa4c56184, AlreadyExistsException: Stack [eksctl-test-cluster-cluster] already exists
Error: failed to create cluster "test-cluster"
[ec2-user@ip-172-31-28-131 ~]$ eksctl create cluster --name test-cluster2 --version 1.23 --region us-west-2 --nodegroup-name linux-nodes --node-type t2.micro --nodes 1
2022-08-29 18:34:25 [ℹ]  eksctl version 0.109.0
2022-08-29 18:34:25 [ℹ]  using region us-west-2
2022-08-29 18:34:25 [ℹ]  skipping us-west-2d from selection because it doesn't support the following instance type(s): t2.micro
2022-08-29 18:34:25 [ℹ]  setting availability zones to [us-west-2a us-west-2c us-west-2b]
2022-08-29 18:34:25 [ℹ]  subnets for us-west-2a - public:192.168.0.0/19 private:192.168.96.0/19
2022-08-29 18:34:25 [ℹ]  subnets for us-west-2c - public:192.168.32.0/19 private:192.168.128.0/19
2022-08-29 18:34:25 [ℹ]  subnets for us-west-2b - public:192.168.64.0/19 private:192.168.160.0/19
2022-08-29 18:34:25 [ℹ]  nodegroup "linux-nodes" will use "" [AmazonLinux2/1.23]
2022-08-29 18:34:25 [ℹ]  using Kubernetes version 1.23
2022-08-29 18:34:25 [ℹ]  creating EKS cluster "test-cluster2" in "us-west-2" region with managed nodes
2022-08-29 18:34:25 [ℹ]  will create 2 separate CloudFormation stacks for cluster itself and the initial managed nodegroup
2022-08-29 18:34:25 [ℹ]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-west-2 --cluster=test-cluster2'
2022-08-29 18:34:25 [ℹ]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "test-cluster2" in "us-west-2"
2022-08-29 18:34:25 [ℹ]  CloudWatch logging will not be enabled for cluster "test-cluster2" in "us-west-2"
2022-08-29 18:34:25 [ℹ]  you can enable it with 'eksctl utils update-cluster-logging --enable-types={SPECIFY-YOUR-LOG-TYPES-HERE (e.g. all)} --region=us-west-2 --cluster=test-cluster2'
2022-08-29 18:34:25 [ℹ]
2 sequential tasks: { create cluster control plane "test-cluster2",
    2 sequential sub-tasks: {
        wait for control plane to become ready,
        create managed nodegroup "linux-nodes",
    }
}
2022-08-29 18:34:25 [ℹ]  building cluster stack "eksctl-test-cluster2-cluster"
2022-08-29 18:34:26 [ℹ]  deploying stack "eksctl-test-cluster2-cluster"
2022-08-29 18:34:56 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-cluster"
2022-08-29 18:35:26 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-cluster"
2022-08-29 18:36:26 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-cluster"
2022-08-29 18:37:26 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-cluster"
2022-08-29 18:38:26 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-cluster"
2022-08-29 18:39:26 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-cluster"
2022-08-29 18:40:26 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-cluster"
2022-08-29 18:41:26 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-cluster"
2022-08-29 18:42:26 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-cluster"

2022-08-29 18:43:26 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-cluster"
2022-08-29 18:44:26 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-cluster"
2022-08-29 18:45:26 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-cluster"
2022-08-29 18:47:27 [ℹ]  building managed nodegroup stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 18:47:27 [ℹ]  deploying stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 18:47:27 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 18:47:57 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 18:48:51 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"

2022-08-29 18:50:40 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 18:52:24 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 18:52:24 [ℹ]  waiting for the control plane availability...
2022-08-29 18:52:25 [✔]  saved kubeconfig as "/home/ec2-user/.kube/config"
2022-08-29 18:52:25 [ℹ]  no tasks
2022-08-29 18:52:25 [✔]  all EKS cluster resources for "test-cluster2" have been created
2022-08-29 18:52:25 [ℹ]  nodegroup "linux-nodes" has 1 node(s)
2022-08-29 18:52:25 [ℹ]  node "ip-192-168-10-198.us-west-2.compute.internal" is ready
2022-08-29 18:52:25 [ℹ]  waiting for at least 1 node(s) to become ready in "linux-nodes"
2022-08-29 18:52:25 [ℹ]  nodegroup "linux-nodes" has 1 node(s)
2022-08-29 18:52:25 [ℹ]  node "ip-192-168-10-198.us-west-2.compute.internal" is ready
2022-08-29 18:52:27 [ℹ]  kubectl command should work with "/home/ec2-user/.kube/config", try 'kubectl get nodes'
2022-08-29 18:52:27 [✔]  EKS cluster "test-cluster2" in "us-west-2" region is ready
[ec2-user@ip-172-31-28-131 ~]$
[ec2-user@ip-172-31-28-131 ~]$
[ec2-user@ip-172-31-28-131 ~]$ kubectl /home/ec2-user/.kube/config
error: unknown command "/home/ec2-user/.kube/config" for "kubectl"
[ec2-user@ip-172-31-28-131 ~]$ kubectl get nodes
NAME                                           STATUS   ROLES    AGE     VERSION
ip-192-168-10-198.us-west-2.compute.internal   Ready    <none>   2m55s   v1.23.9-eks-ba74326
[ec2-user@ip-172-31-28-131 ~]$ cat /home/ec2-user/.kube/config
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeU1EZ3lPVEU0TkRBek9Wb1hEVE15TURneU5qRTROREF6T1Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTkhHClpOQU9HTkRkcTMraHgwUHR3UGRoWDhnQ0VQRVJUSEkreWtmeGQ3ZEpiR083M3ArNms0WFZlOHBKTjF5NUVTcTIKclNKQUV1dDJkNGo3eWsvMDNZRFpXR1VESjd0Z1N2YkVOSEFoL1hVQW85OFZPVEFObk9pM2RhTVkrN0hKbXBOVQpkblJyWEU2Uk1iV05rZldQUlViZUtqQ1hDb0FmMDZSVE14TVpPbTBGYnZ6Q1FONFdhQXZ0OGZNMTJ2NCtLQ2NiCkpaUG5OMWJUMnhkYXVvUnkxZkFocE43VkRDMVRsamRwdG5tNW44Y21PSEl6R1lscEp5NVkvcFg3Ym95YmpYVFQKT3JZdUZMcU5RcVBoVUlURDFrVW45K2FoTVBuOUdIUnMzQ1hLc085ajRZQWw4d3UxUFEzS2h5UUlkb2poL041dgpvYzhFRWlWdGp1dmJvTWVpNzFzQ0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZJUnNGT3RIWUJKaE11amx1TUtLaVlML2Q3WkZNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBR1NuaWx6T2NGRkFCYzZyNlRXWQpTSlM3bG0wQTNzTzJGNGRhV05JZVhNZS95bzcvbDNDM3Fxelk4QVhVUExJNVk1bk1vR2JoK3I2Szg4b2VXaWQ2CmU5TjgwUGtxRjJrc2tiaVM4dDBtVEVHRzlqR3oxdEs5VHNjSG1xMnZLZFFjNzhYUXJEQ0RBc2lNYnA0dWYvdWwKOFVWSmZ5Umczako5b2RjUWRzMWRrY1VCUm5WV0x5b1A5LzQzaExuRUI4ZUdxZ0xrNEVRNGJQOGpHTE93M1VUNgpKNGdmclhlNGx6cHpGTlpXSEFydDR3Wno5YUpRREdUck9mQ0k0YVlBSWE5ZmFseEJMN2xmTFBGNGJkNHJ3cDB6CmZnOENtbDhJUmVnLzIrRUgwNUJzUDBHTjJEMURLcDVnOGoxckQ5QnJRVXVjeVJ6UEY2VlJGUVlMQzVHditlT2sKVGdnPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
    server: https://082F6258E2ADBD897FE10C8970BB52B3.yl4.us-west-2.eks.amazonaws.com
  name: test-cluster2.us-west-2.eksctl.io
contexts:
- context:
    cluster: test-cluster2.us-west-2.eksctl.io
    user: i-0287972da825e3a88@test-cluster2.us-west-2.eksctl.io
  name: i-0287972da825e3a88@test-cluster2.us-west-2.eksctl.io
current-context: i-0287972da825e3a88@test-cluster2.us-west-2.eksctl.io
kind: Config
preferences: {}
users:
- name: i-0287972da825e3a88@test-cluster2.us-west-2.eksctl.io
  user:
    exec:
      apiVersion: client.authentication.k8s.io/v1beta1
      args:
      - eks
      - get-token
      - --cluster-name
      - test-cluster2
      - --region
      - us-west-2
      command: aws
      env:
      - name: AWS_STS_REGIONAL_ENDPOINTS
        value: regional
      provideClusterInfo: false
[ec2-user@ip-172-31-28-131 ~]$ kubectl create ns test
namespace/test created
[ec2-user@ip-172-31-28-131 ~]$ kubectl get svc
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.100.0.1   <none>        443/TCP   14m
[ec2-user@ip-172-31-28-131 ~]$ kubectl get all
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.100.0.1   <none>        443/TCP   14m
[ec2-user@ip-172-31-28-131 ~]$ curl http://10.100.0.1:8081
^C
[ec2-user@ip-172-31-28-131 ~]$ kubectl get pods
No resources found in default namespace.
[ec2-user@ip-172-31-28-131 ~]$ kubectl ns
error: unknown command "ns" for "kubectl"

Did you mean this?
        cp
[ec2-user@ip-172-31-28-131 ~]$ kubectl get ns
NAME              STATUS   AGE
default           Active   16m
kube-node-lease   Active   16m
kube-public       Active   16m
kube-system       Active   16m
test              Active   2m43s
[ec2-user@ip-172-31-28-131 ~]$ kubectl test
error: unknown command "test" for "kubectl"

Did you mean this?
        set
        get
[ec2-user@ip-172-31-28-131 ~]$ kubectl ns test
error: unknown command "ns" for "kubectl"

Did you mean this?
        cp
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment
No resources found in default namespace.
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           4m26s
[ec2-user@ip-172-31-28-131 ~]$ kubectl delete deployment --namespace=test
error: resource(s) were provided, but no name was specified
[ec2-user@ip-172-31-28-131 ~]$ kubectl delete deployment simple-web-app  --namespace=test
deployment.apps "simple-web-app" deleted
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           5s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           14s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           17s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get svc --namespace=test
NAME                     TYPE           CLUSTER-IP      EXTERNAL-IP                                                               PORT(S)          AGE
simple-web-app-service   LoadBalancer   10.100.201.45   a2058bc077c424e2196a0b6f2313461e-1588959590.us-west-2.elb.amazonaws.com   9393:32509/TCP   6m14s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get svc --namespace=test
NAME                     TYPE           CLUSTER-IP      EXTERNAL-IP                                                               PORT(S)          AGE
simple-web-app-service   LoadBalancer   10.100.201.45   a2058bc077c424e2196a0b6f2313461e-1588959590.us-west-2.elb.amazonaws.com   9393:32509/TCP   8m55s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           3m19s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           4m36s
[ec2-user@ip-172-31-28-131 ~]$ kubectl delete deployment simple-web-app  --namespace=test
deployment.apps "simple-web-app" deleted
[ec2-user@ip-172-31-28-131 ~]$ kubectl delete deployment simple-web-app  --namespace=test
Error from server (NotFound): deployments.apps "simple-web-app" not found
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           8s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           11s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           13s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           16s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           18s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           21s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           24s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           29s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           32s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           34s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           2m52s
[ec2-user@ip-172-31-28-131 ~]$ kubectl delete deployment simple-web-app  --namespace=test
deployment.apps "simple-web-app" deleted
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
No resources found in test namespace.
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           11s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           14s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           18s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           20s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           23s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           25s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           27s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           29s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           32s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           34s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           9m28s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           16m
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
simple-web-app   0/1     1            0           17m
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
my-springboot-deployment   0/1     1            0           4s
simple-web-app             0/1     1            0           17m
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
my-springboot-deployment   0/1     1            0           9s
simple-web-app             0/1     1            0           17m
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
my-springboot-deployment   0/1     1            0           12s
simple-web-app             0/1     1            0           17m
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
my-springboot-deployment   0/1     1            0           16s
simple-web-app             0/1     1            0           18m
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
my-springboot-deployment   0/1     1            0           18s
simple-web-app             0/1     1            0           18m
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
my-springboot-deployment   0/1     1            0           22s
simple-web-app             0/1     1            0           18m
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
my-springboot-deployment   0/1     1            0           44s
simple-web-app             0/1     1            0           18m
[ec2-user@ip-172-31-28-131 ~]$ kubectl logs deployment/simple-web-app
Error from server (NotFound): deployments.apps "simple-web-app" not found
[ec2-user@ip-172-31-28-131 ~]$ kubectl logs deployment/my=springboot-deployment -namespace=test
Error from server (NotFound): namespaces "amespace=test" not found
[ec2-user@ip-172-31-28-131 ~]$ kubectl logs deployment/my=springboot-deployment --namespace=test
Error from server (NotFound): deployments.apps "my=springboot-deployment" not found
[ec2-user@ip-172-31-28-131 ~]$ kubectl logs deployment/my=springboot-deployment
Error from server (NotFound): deployments.apps "my=springboot-deployment" not found
[ec2-user@ip-172-31-28-131 ~]$ kubectl logs deployment/my-springboot-deployment
Error from server (NotFound): deployments.apps "my-springboot-deployment" not found
[ec2-user@ip-172-31-28-131 ~]$ kubectl logs deployment/my-springboot-deployment --namespace=test
[ec2-user@ip-172-31-28-131 ~]$ kubectl logs -f deployment/my-springboot-deployment --namespace=test
[ec2-user@ip-172-31-28-131 ~]$ kubectl get deployment --namespace=test
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
my-springboot-deployment   0/1     1            0           2m41s
simple-web-app             0/1     1            0           20m
[ec2-user@ip-172-31-28-131 ~]$ kubectl get pods
No resources found in default namespace.
[ec2-user@ip-172-31-28-131 ~]$ kubectl get pods --namespace=test
NAME                                       READY   STATUS    RESTARTS   AGE
my-springboot-deployment-cc99f7f5f-s9ghp   0/1     Pending   0          3m29s
simple-web-app-664465b866-jh6lq            0/1     Pending   0          21m
[ec2-user@ip-172-31-28-131 ~]$ kubectl logs simple-web-app-664465b866-jh6lq
Error from server (NotFound): pods "simple-web-app-664465b866-jh6lq" not found
[ec2-user@ip-172-31-28-131 ~]$ kubectl logs simple-web-app-664465b866-jh6lq^C
[ec2-user@ip-172-31-28-131 ~]$ eksctl delete cluster --name=test-cluster2
2022-08-29 19:35:45 [ℹ]  deleting EKS cluster "test-cluster2"
2022-08-29 19:35:46 [ℹ]  will drain 0 unmanaged nodegroup(s) in cluster "test-cluster2"
2022-08-29 19:35:46 [ℹ]  starting parallel draining, max in-flight of 1
2022-08-29 19:35:46 [ℹ]  deleted 0 Fargate profile(s)
2022-08-29 19:35:46 [✔]  kubeconfig has been updated
2022-08-29 19:35:46 [ℹ]  cleaning up AWS load balancers created by Kubernetes objects of Kind Service or Ingress
2022-08-29 19:36:35 [ℹ]
2 sequential tasks: { delete nodegroup "linux-nodes", delete cluster control plane "test-cluster2" [async]
}
2022-08-29 19:36:35 [ℹ]  will delete stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 19:36:35 [ℹ]  waiting for stack "eksctl-test-cluster2-nodegroup-linux-nodes" to get deleted
2022-08-29 19:36:35 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 19:37:05 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 19:37:42 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 19:38:49 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 19:39:41 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 19:41:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 19:42:24 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 19:44:24 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 19:44:57 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster2-nodegroup-linux-nodes"
2022-08-29 19:44:57 [ℹ]  will delete stack "eksctl-test-cluster2-cluster"
2022-08-29 19:44:57 [✔]  all cluster resources were deleted
[ec2-user@ip-172-31-28-131 ~]$ eksctl create cluster --name test-cluster2 --version 1.23 --region us-west-2 --nodegroup-name linux-nodes --node-type t2.micro --nodes 2
2022-08-29 19:45:57 [ℹ]  eksctl version 0.109.0
2022-08-29 19:45:57 [ℹ]  using region us-west-2
2022-08-29 19:45:57 [ℹ]  skipping us-west-2d from selection because it doesn't support the following instance type(s): t2.micro
2022-08-29 19:45:57 [ℹ]  setting availability zones to [us-west-2b us-west-2a us-west-2c]
2022-08-29 19:45:57 [ℹ]  subnets for us-west-2b - public:192.168.0.0/19 private:192.168.96.0/19
2022-08-29 19:45:57 [ℹ]  subnets for us-west-2a - public:192.168.32.0/19 private:192.168.128.0/19
2022-08-29 19:45:57 [ℹ]  subnets for us-west-2c - public:192.168.64.0/19 private:192.168.160.0/19
2022-08-29 19:45:57 [ℹ]  nodegroup "linux-nodes" will use "" [AmazonLinux2/1.23]
2022-08-29 19:45:57 [ℹ]  using Kubernetes version 1.23
2022-08-29 19:45:57 [ℹ]  creating EKS cluster "test-cluster2" in "us-west-2" region with managed nodes
2022-08-29 19:45:57 [ℹ]  will create 2 separate CloudFormation stacks for cluster itself and the initial managed nodegroup
2022-08-29 19:45:57 [ℹ]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-west-2 --cluster=test-cluster2'
2022-08-29 19:45:57 [ℹ]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "test-cluster2" in "us-west-2"
2022-08-29 19:45:57 [ℹ]  CloudWatch logging will not be enabled for cluster "test-cluster2" in "us-west-2"
2022-08-29 19:45:57 [ℹ]  you can enable it with 'eksctl utils update-cluster-logging --enable-types={SPECIFY-YOUR-LOG-TYPES-HERE (e.g. all)} --region=us-west-2 --cluster=test-cluster2'
2022-08-29 19:45:57 [ℹ]
2 sequential tasks: { create cluster control plane "test-cluster2",
    2 sequential sub-tasks: {
        wait for control plane to become ready,
        create managed nodegroup "linux-nodes",
    }
}
2022-08-29 19:45:57 [ℹ]  building cluster stack "eksctl-test-cluster2-cluster"
2022-08-29 19:45:57 [!]  1 error(s) occurred and cluster hasn't been created properly, you may wish to check CloudFormation console
2022-08-29 19:45:57 [ℹ]  to cleanup resources, run 'eksctl delete cluster --region=us-west-2 --name=test-cluster2'
2022-08-29 19:45:57 [✖]  creating CloudFormation stack "eksctl-test-cluster2-cluster": operation error CloudFormation: CreateStack, https response error StatusCode: 400, RequestID: 8f3e7a17-eac5-4a41-9812-4f1b1b9fdd1d, AlreadyExistsException: Stack [eksctl-test-cluster2-cluster] already exists
Error: failed to create cluster "test-cluster2"
[ec2-user@ip-172-31-28-131 ~]$ eksctl create cluster --name test-cluster3 --version 1.23 --region us-west-2 --nodegroup-name linux-nodes --node-type t2.micro --nodes 2
2022-08-29 19:46:15 [ℹ]  eksctl version 0.109.0
2022-08-29 19:46:15 [ℹ]  using region us-west-2
2022-08-29 19:46:15 [ℹ]  skipping us-west-2d from selection because it doesn't support the following instance type(s): t2.micro
2022-08-29 19:46:15 [ℹ]  setting availability zones to [us-west-2a us-west-2c us-west-2b]
2022-08-29 19:46:15 [ℹ]  subnets for us-west-2a - public:192.168.0.0/19 private:192.168.96.0/19
2022-08-29 19:46:15 [ℹ]  subnets for us-west-2c - public:192.168.32.0/19 private:192.168.128.0/19
2022-08-29 19:46:15 [ℹ]  subnets for us-west-2b - public:192.168.64.0/19 private:192.168.160.0/19
2022-08-29 19:46:15 [ℹ]  nodegroup "linux-nodes" will use "" [AmazonLinux2/1.23]
2022-08-29 19:46:15 [ℹ]  using Kubernetes version 1.23
2022-08-29 19:46:15 [ℹ]  creating EKS cluster "test-cluster3" in "us-west-2" region with managed nodes
2022-08-29 19:46:15 [ℹ]  will create 2 separate CloudFormation stacks for cluster itself and the initial managed nodegroup
2022-08-29 19:46:15 [ℹ]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-west-2 --cluster=test-cluster3'
2022-08-29 19:46:15 [ℹ]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "test-cluster3" in "us-west-2"
2022-08-29 19:46:15 [ℹ]  CloudWatch logging will not be enabled for cluster "test-cluster3" in "us-west-2"
2022-08-29 19:46:15 [ℹ]  you can enable it with 'eksctl utils update-cluster-logging --enable-types={SPECIFY-YOUR-LOG-TYPES-HERE (e.g. all)} --region=us-west-2 --cluster=test-cluster3'
2022-08-29 19:46:15 [ℹ]
2 sequential tasks: { create cluster control plane "test-cluster3",
    2 sequential sub-tasks: {
        wait for control plane to become ready,
        create managed nodegroup "linux-nodes",
    }
}
2022-08-29 19:46:15 [ℹ]  building cluster stack "eksctl-test-cluster3-cluster"
2022-08-29 19:46:16 [ℹ]  deploying stack "eksctl-test-cluster3-cluster"
2022-08-29 19:46:46 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 19:47:16 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 19:48:16 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 19:49:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 19:50:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 19:51:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 19:52:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 19:53:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 19:54:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 19:55:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 19:56:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 19:57:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 19:58:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 19:59:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 20:00:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 20:01:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"
2022-08-29 20:02:19 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-cluster"


2022-08-29 20:04:20 [ℹ]  building managed nodegroup stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:04:20 [ℹ]  deploying stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:04:20 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:04:50 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:05:29 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-nodegroup-linux-nodes"



2022-08-29 20:06:41 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:08:36 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:08:36 [ℹ]  waiting for the control plane availability...
2022-08-29 20:08:37 [✔]  saved kubeconfig as "/home/ec2-user/.kube/config"
2022-08-29 20:08:37 [ℹ]  no tasks
2022-08-29 20:08:37 [✔]  all EKS cluster resources for "test-cluster3" have been created
2022-08-29 20:08:37 [ℹ]  nodegroup "linux-nodes" has 2 node(s)
2022-08-29 20:08:37 [ℹ]  node "ip-192-168-1-194.us-west-2.compute.internal" is ready
2022-08-29 20:08:37 [ℹ]  node "ip-192-168-77-133.us-west-2.compute.internal" is ready
2022-08-29 20:08:37 [ℹ]  waiting for at least 2 node(s) to become ready in "linux-nodes"
2022-08-29 20:08:37 [ℹ]  nodegroup "linux-nodes" has 2 node(s)
2022-08-29 20:08:37 [ℹ]  node "ip-192-168-1-194.us-west-2.compute.internal" is ready
2022-08-29 20:08:37 [ℹ]  node "ip-192-168-77-133.us-west-2.compute.internal" is ready
2022-08-29 20:08:39 [ℹ]  kubectl command should work with "/home/ec2-user/.kube/config", try 'kubectl get nodes'
2022-08-29 20:08:39 [✔]  EKS cluster "test-cluster3" in "us-west-2" region is ready
[ec2-user@ip-172-31-28-131 ~]$
[ec2-user@ip-172-31-28-131 ~]$
[ec2-user@ip-172-31-28-131 ~]$
[ec2-user@ip-172-31-28-131 ~]$
[ec2-user@ip-172-31-28-131 ~]$
[ec2-user@ip-172-31-28-131 ~]$ cat /home/ec2-user/.kube/config
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJeU1EZ3lPVEU1TlRJME4xb1hEVE15TURneU5qRTVOVEkwTjFvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTnQ2CmR2R2JXbXl5RmRIbDRBWm1XTVhGVERqR0grQ05kSENQYW1uZ3JORjMrOWRTNnl3VlNGRlBWK1FyNGxySzB4dmQKMlAxRWRTU2JuQVE5MkkreW5ZUzBld0ZBTnA5WkZqRk5wM2N0UVFvYzdKTEpxemhpbmFINVQwM21vb0Y0M1lJLwpxZU85VWp2RUJ0NVlkYWR1WmhHc2lmRXlmaGxtL3NhaHZqVmZpaWFneHV2UHlna3RPQUtkN2JKVXF5NjdxZGw1CllHZFFQZmc1bHpoRmhIQTlFcEVDM1ZLbU9laFFCcXpZc2dTTER2cGhrclE0QmdnNkU5UnZBYksrSkNpYWsxTGcKUFcyRDQwaTNBSUY2NFg2TTEwRGh3OVN2dGk5UlNIZi9vQkJTaXlINmxrajIvckxLaGZFV0NPa0lPZGROQjZnTQpnN2VXWXk5ekZSUExuaUlhY2c4Q0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZDdndLeUhJMjhaZDM4d0ZpR3p1SVVhT25DbzVNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBSlBNSXFYVkpVdUFMSHM4NmtSdApYbmhXVHBzZk5uYndvQm14Y0VQeStsekp3T3Z5NEJ4M2NVQmlhSU0xUWNzY2NNVFh5a1k3KzZhSFhBb1pVVlhoCmhtaE1SUWZKMUhQRnFyNkZvR0E0OUh6OXpUWEFFeUM4S0RlaDhUZ3RmS2pJUDlOS1E4Q1Q0SUZqVjVtZTlUaGQKVjBGOWNGSkhGaytib01ublJ4ZHdweHpubkR4MVh6QytTMThrQm9NczBJRS90aFgxM0h5UkVKanFNclJBeTRVbgpZOWtBS0xqcldHUDZEWVFneExYNSs1Q09BQ1NhcDV1ZnRJbUg1VkkvSzhvUUVZTmlHY1c1WEJWdzcrZVg1NUxOClNXTjNNcFI4UnREbVNrcGpzRXFscE9nSHZlTmMwK0doZmh5aXgrOEhNMjFJQ2dWdnA2MEFrbHh0SUNiME4xK24KMTRVPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
    server: https://BE5711FC73DA79D89C32DF5C9ADB72C1.gr7.us-west-2.eks.amazonaws.com
  name: test-cluster3.us-west-2.eksctl.io
contexts:
- context:
    cluster: test-cluster3.us-west-2.eksctl.io
    user: i-0287972da825e3a88@test-cluster3.us-west-2.eksctl.io
  name: i-0287972da825e3a88@test-cluster3.us-west-2.eksctl.io
current-context: i-0287972da825e3a88@test-cluster3.us-west-2.eksctl.io
kind: Config
preferences: {}
users:
- name: i-0287972da825e3a88@test-cluster3.us-west-2.eksctl.io
  user:
    exec:
      apiVersion: client.authentication.k8s.io/v1beta1
      args:
      - eks
      - get-token
      - --cluster-name
      - test-cluster3
      - --region
      - us-west-2
      command: aws
      env:
      - name: AWS_STS_REGIONAL_ENDPOINTS
        value: regional
      provideClusterInfo: false
[ec2-user@ip-172-31-28-131 ~]$ kubectl get pods
No resources found in default namespace.
[ec2-user@ip-172-31-28-131 ~]$ kubectl create namespace=test
Error: must specify one of -f and -k

error: unknown command "namespace=test"
See 'kubectl create -h' for help and examples
[ec2-user@ip-172-31-28-131 ~]$ kubectl create namespace test
namespace/test created
[ec2-user@ip-172-31-28-131 ~]$ kubectl get pods --namespace=test
No resources found in test namespace.
[ec2-user@ip-172-31-28-131 ~]$ kubectl get pods --namespace=test
NAME                                       READY   STATUS              RESTARTS   AGE
my-springboot-deployment-cc99f7f5f-h7m6x   0/1     ContainerCreating   0          4s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get pods --namespace=test
NAME                                       READY   STATUS              RESTARTS   AGE
my-springboot-deployment-cc99f7f5f-h7m6x   0/1     ContainerCreating   0          9s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get pods --namespace=test
NAME                                       READY   STATUS              RESTARTS   AGE
my-springboot-deployment-cc99f7f5f-h7m6x   0/1     ContainerCreating   0          12s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get pods --namespace=test
NAME                                       READY   STATUS    RESTARTS   AGE
my-springboot-deployment-cc99f7f5f-h7m6x   1/1     Running   0          21s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get svc --namespace=test
NAME             TYPE           CLUSTER-IP    EXTERNAL-IP                                                              PORT(S)        AGE
springboot-app   LoadBalancer   10.100.74.3   a53596038bedf4311914d1396c8b916f-873831139.us-west-2.elb.amazonaws.com   80:30369/TCP   57s
[ec2-user@ip-172-31-28-131 ~]$ a53596038bedf4311914d1396c8b916f-873831139.us-west-2.elb.amazonaws.com^C
[ec2-user@ip-172-31-28-131 ~]$ kubectl get svc --namespace=test
NAME                     TYPE           CLUSTER-IP       EXTERNAL-IP                                                              PORT(S)          AGE
simple-web-app-service   LoadBalancer   10.100.148.109   a6c5e4616494a407aa70cb18ad6e2895-9004122.us-west-2.elb.amazonaws.com     9393:31969/TCP   13s
springboot-app           LoadBalancer   10.100.74.3      a53596038bedf4311914d1396c8b916f-873831139.us-west-2.elb.amazonaws.com   80:30369/TCP     4m7s
[ec2-user@ip-172-31-28-131 ~]$ kubectl get pods --namespace=test
NAME                                       READY   STATUS    RESTARTS   AGE
my-springboot-deployment-cc99f7f5f-h7m6x   1/1     Running   0          4m18s
simple-web-app-664465b866-t8d9n            1/1     Running   0          24s
[ec2-user@ip-172-31-28-131 ~]$ eksctl delete cluster --name=test-cluster3
2022-08-29 20:18:06 [ℹ]  deleting EKS cluster "test-cluster3"
2022-08-29 20:18:06 [ℹ]  will drain 0 unmanaged nodegroup(s) in cluster "test-cluster3"
2022-08-29 20:18:06 [ℹ]  starting parallel draining, max in-flight of 1
2022-08-29 20:18:06 [ℹ]  deleted 0 Fargate profile(s)
2022-08-29 20:18:06 [✔]  kubeconfig has been updated
2022-08-29 20:18:06 [ℹ]  cleaning up AWS load balancers created by Kubernetes objects of Kind Service or Ingress
2022-08-29 20:19:17 [ℹ]
2 sequential tasks: { delete nodegroup "linux-nodes", delete cluster control plane "test-cluster3" [async]
}
2022-08-29 20:19:17 [ℹ]  will delete stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:19:17 [ℹ]  waiting for stack "eksctl-test-cluster3-nodegroup-linux-nodes" to get deleted
2022-08-29 20:19:17 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:19:47 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:20:22 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:22:16 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:22:53 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-nodegroup-linux-nodes"

2022-08-29 20:24:29 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:25:01 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:26:09 [ℹ]  waiting for CloudFormation stack "eksctl-test-cluster3-nodegroup-linux-nodes"
2022-08-29 20:26:09 [ℹ]  will delete stack "eksctl-test-cluster3-cluster"
2022-08-29 20:26:09 [✔]  all cluster resources were deleted
[ec2-user@ip-172-31-28-131 ~]$
[ec2-user@ip-172-31-28-131 ~]$
